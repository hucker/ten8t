# WARNING:
#
# The sorting and recursive restruturing of the data in this file was generated by AI Assistant


import json

THRESHOLDS = {
    "bugs": [(0.05, "A"), (0.1, "B"), (0.2, "C"), (0.3, "D")],  # (Upper bound, Grade)
    "difficulty": [(10, "A"), (20, "B"), (30, "C"), (40, "D")],
    "effort": [(1000, "A"), (2000, "B"), (5000, "C"), (10000, "D")],
    "time": [(50, "A"), (100, "B"), (200, "C"), (500, "D")],
}


def evaluate_metric(value: float, metric: str, thresholds: dict = THRESHOLDS) -> str:
    """
    Evaluate a value against the thresholds of a specific metric.

    Args:
        value (float): The value to be graded.
        metric (str): The name of the metric (e.g., "bugs", "difficulty").
        thresholds (dict): A dictionary of thresholds for all metrics.

    Returns:
        str: The grade (A, B, C, D, F).
    """
    if metric not in thresholds:
        raise ValueError(f"Unknown metric: {metric}")

    if value < 0:
        return "ERR"  # Handle invalid values
    for upper_bound, grade in thresholds[metric]:
        if value <= upper_bound:
            return grade
    return "F"  # F is the default grade if no thresholds matched


def grade_metrics(value_dict: dict) -> dict:
    """
    Grade multiple metrics.

    Args:
        value_dict (dict): A dictionary of metrics and their respective values.
            Example: {'bugs': 0.12, 'difficulty': 25, 'effort': 3400, 'time': 80}

    Returns:
        dict: A dictionary of metrics and their respective grades.
            Example: {'bugs': 'B', 'difficulty': 'C', 'effort': 'C', 'time': 'B'}
    """
    return {metric: evaluate_metric(value, metric) for metric, value in value_dict.items()}


def transform_keys(obj, search_prefix, replace_with=""):
    """
    Recursively transform keys in a JSON object.

    Args:
        obj: The JSON object (dict, list, or primitive value)
        search_prefix: The prefix to search for in keys
        replace_with: The string to replace the prefix with (default: empty string)

    Returns:
        Transformed object with keys replaced
    """
    if isinstance(obj, dict):
        new_obj = {}
        for key, value in obj.items():
            # Transform the key if it starts with the search prefix
            new_key = key.replace(search_prefix, replace_with) if isinstance(key, str) and key.startswith(
                search_prefix) else key
            # Recursively process the value
            new_obj[new_key] = transform_keys(value, search_prefix, replace_with)
        return new_obj
    elif isinstance(obj, list):
        # Process each item in the list
        return [transform_keys(item, search_prefix, replace_with) for item in obj]
    else:
        # Return primitive values as is
        return obj


def load_json(file):
    with open(file, "r") as f:
        json_data = json.load(f)
    json_data = transform_keys(json_data, "../src/ten8t/", "")
    return json_data


def mi_to_table(
        input_file="snippets/radon_mi.json",
        output_file="snippets/radon_mi.csv",
        sort_by_mi=True,
        reverse=False
):
    """
    Process Maintainability Index data and output sorted CSV.

    Args:
        input_file (str): Path to input JSON file.
        output_file (str): Path to output CSV file.
        sort_by_mi (bool): Enables sorting by Maint. Index descending when True.
    """
    try:
        with open(input_file, "r") as f:
            jd = json.load(f)

        rows = []

        # Gather data into a list
        for fname, data in jd.items():
            short_fname = fname.split("/")[-1]
            maint_index = float(data['mi'])
            rank = data['rank']
            rows.append({
                "File": short_fname,
                "Maint. Index": maint_index,
                "Rank": rank
            })

        # Sort by Maint. Index descending if enabled
        if sort_by_mi:
            rows.sort(key=lambda x: x["Maint. Index"], reverse=reverse)

        # Write sorted data into CSV
        with open(output_file, "w") as of:
            of.write("File,Maint. Index,Rank\n")
            for row in rows:
                of.write(f"{row['File']},{row['Maint. Index']:.1f},{row['Rank']}\n")

    except Exception as e:
        print(f"Error processing Maint. Index metrics: {e}")


def cc_to_table(input_file="snippets/radon_cc.json",
                output_file="snippets/radon_cc.csv",
                sort_by_complexity=True,
                reverse=True):
    """
    Process complexity JSON and produce sorted CSV by complexity (max to min).

    Args:
        input_file (str): Path to input complexity JSON file.
        output_file (str): Path to CSV output.
        sort_by_complexity (bool): Sort by complexity in descending order if True.
    """
    try:
        with open(input_file, 'r') as f:
            jd = json.load(f)

        # List to hold all rows before writing to CSV
        rows_list = []

        # Collect data
        for fname, items in jd.items():
            short_fname = fname.split("/")[-1]
            for item in items:
                try:
                    if item['type'] == 'class':
                        rows_list.append({
                            "File": short_fname,
                            "Name": item['name'],
                            "Rank": item['rank'],
                            "Complexity": float(item['complexity'])
                        })
                except Exception as e:
                    print(f"Error processing {fname}: {str(e)}")

        # Optional sorting by complexity
        if sort_by_complexity:
            rows_list.sort(key=lambda x: x["Complexity"], reverse=reverse)

        # Write sorted CSV output
        with open(output_file, "w") as of:
            of.write("File,Name,Rank,Complexity\n")
            for row in rows_list:
                of.write(f"{row['File']},{row['Name']},{row['Rank']},{row['Complexity']:.1f}\n")

    except Exception as e:
        print(f"Error processing complexity metrics: {e}")


#
# def bug_thresh(value: float) -> str:
#     if value <= 0.05:
#         return 'A'
#     elif value <= 0.1:
#         return 'B'
#     elif value <= 0.2:
#         return 'C'
#     elif value <= 0.3:
#         return 'D'
#     else:
#         return 'F'
#
#
# def difficulty_thresh(value: float) -> str:
#     if value <= 10.0:
#         return 'A'
#     elif value <= 20:
#         return 'B'
#     elif value <= 30:
#         return 'C'
#     elif value <= 40:
#         return 'D'
#     else:
#         return 'F'
#
#
# def effort_thresh(value: float) -> str:
#     if value <= 1000.0:
#         return 'A'
#     elif value <= 2000:
#         return 'B'
#     elif value <= 5000:
#         return 'C'
#     elif value <= 10000:
#         return 'D'
#     else:
#         return 'F'
#
#
# def time_thresh(value: float) -> str:
#     if value <= 50.0:
#         return 'A'
#     elif value <= 100:
#         return 'B'
#     elif value <= 200:
#         return 'C'
#     elif value <= 5000:
#         return 'D'
#     else:
#         return 'F'


def hal_to_table(input_file="snippets/radon_hal.json",
                 output_file="snippets/radon_hal.csv",
                 sort_by="bugs"):
    """
    Process Halstead metrics and include grades in CSV output, sorted by a specified column (default "bugs").

    Args:
        input_file (str): Path to input JSON file.
        output_file (str): Path to output CSV file.
        sort_by (str): Column to sort by, default is "bugs".
    """
    try:
        with open(input_file, "r") as f:
            jd = json.load(f)

        columns = ["file", "bugs", "difficulty", "effort", "time"]
        grade_columns = [f"{col}_rank" for col in columns if col != "file"]
        all_cols = [col.title() for col in columns + grade_columns]

        rows = []

        for fname, data in jd.items():
            short_fname = fname.split("/")[-1]

            if "total" in data:
                metrics = {col: float(data["total"][col]) for col in columns if col != "file"}
                grades = grade_metrics(metrics)
                numeric_values = [f"{metrics[col]}" for col in metrics]
                grade_values = [grades[col] for col in metrics]
                row = [short_fname] + numeric_values + grade_values

                rows.append(row)

        # Sort by specified column descending (default "bugs")
        if sort_by and sort_by.lower() in columns and sort_by.lower() != "file":
            sort_idx = columns.index(sort_by.lower())
            rows.sort(key=lambda x: float(x[sort_idx]), reverse=True)

        # Write to output CSV
        with open(output_file, "w") as of:
            of.write(",".join(all_cols) + "\n")
            for row in rows:
                of.write(",".join(row) + "\n")

    except Exception as e:
        print(f"Error processing HAL metrics: {e}")


cc_to_table(input_file='snippets/radon_cc.json')
hal_to_table(input_file='snippets/radon_hal.json')
mi_to_table(input_file='snippets/radon_mi.json')
